{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision #has bunch of datasets for vision tasks\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:01, 6854831.62it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 29754909.60it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1649664it [00:00, 4837746.88it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, ?it/s]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test_data = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why batch_size\n",
    "There are two major reasons why you can't just go and pass your entire dataset at once to your neural network:\n",
    "\n",
    "- Neural networks shine and outperform other machine learning techniques because of how well they work on big datasets. Gigabytes. Terabytes. Petabytes! When we're just learning, we tend to play with datasets smaller than a gigabyte, and we can often just toss the entire thing into the VRAM of our GPU or even more likely into RAM.\n",
    "Unfortunately, in practice, you would likely not get away with this.\n",
    "\n",
    "- The aim with neural networks is to have the network generalize with the data. We want the neural network to actually learn general principles. That said, neural networks often have millions, or tens of millions, of parameters that they can tweak to do this. This means neural networks can also just memorize things. While we hope neural networks will generalize, they often learn to just memorize the input data. Our job as the scientist is to make it as hard as possible for the neural network to just memorize.\n",
    "\n",
    "This batching helps because, with each batch, the neural network does a back propagation for new, updated weights with hopes of decreasing that loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 5, 8, 3, 5, 6, 8, 5, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "#Since batch_size is 10 we get 10 samples as output\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 8, 3, 5, 6, 8, 5, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "X, y = data[0][0], data[1][0] #data[0] is a bunch of features for things and data[1] is all the targets.\n",
    "\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOwever if you loaded an image and converted it to grayscale and saved it as tensor you would have got 28*28. But here we get 1*28*28 beacuse that's how pytorch works. Hence we will reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # pip install matplotlib\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "#plt.imshow(data[0][0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for our checklist:\n",
    "\n",
    "- We've got our data of various featuresets and their respective classes.\n",
    "- That data is all numerical.\n",
    "- We've shuffled the data.\n",
    "- We've split the data into training and testing groups.\n",
    "- Is the data scaled? - the neural network likes data to be scaled between 0 and 1 or -1 and 1. Raw imagery data is usually RGB, where each pixel is a tuple of values of 0-255, which is a problem. 0 to 255 is not scaled.\n",
    "- Is the data balanced? - make sure there are the same number of examples for each classifications in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a20f9aec864725aaab65e871419d99cbd7cf3d5ab0d2e7243b7ef9750fa61ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('pixsy_work': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
