{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6LNvHHJHcQ7",
        "outputId": "e2a66109-8e54-483d-8255-94c7eb48b49f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v4hBgU8H98k",
        "outputId": "51d450fe-0d20-4527-c1b7-0b83eedcc741"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-0wkhhhIMQq",
        "outputId": "2df32253-5302-4e46-cc0a-69cdde1eba2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvUTalGAHzhQ",
        "outputId": "1452392d-3e2f-474e-fcdd-5e9dfddc2cce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SD3uttjxG41h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "REBUILD_DATA = True # set to true once, then back to false after you have created/processed your data unless you want to change something in your training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTrrUMdFG41o",
        "outputId": "cef19992-68c1-42b8-d3cd-34ad62460837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 0. 0.]\n",
            "[0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "#creates an array of size 3 and one-hot encodes it at specifies index\n",
        "a=np.eye(3)[0]\n",
        "b=np.eye(3)[2]\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8icS5edG41q",
        "outputId": "f2c62ca3-7d7d-4edc-c1cc-40262a5ef492"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12501/12501 [01:30<00:00, 137.63it/s]\n",
            "100%|██████████| 12501/12501 [01:24<00:00, 147.61it/s]\n",
            "C:\\Users\\shubh\\Desktop\\Pixsy\\ml-retraining\\pixsy_work\\lib\\site-packages\\numpy\\lib\\npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cats: 12476\n",
            "Dogs: 12470\n"
          ]
        }
      ],
      "source": [
        "class DogsVSCats():\n",
        "    IMG_SIZE = 50\n",
        "    CATS = \"PetImages/Cat\"\n",
        "    DOGS = \"PetImages/Dog\"\n",
        "    TESTING = \"PetImages/Testing\"\n",
        "    LABELS = {CATS: 0, DOGS: 1}\n",
        "    training_data = []\n",
        "\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            for f in tqdm(os.listdir(label)):\n",
        "                if \"jpg\" in f:\n",
        "                    try:\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
        "                        #print(np.eye(2)[self.LABELS[label]])\n",
        "                        \n",
        "                        if label == self.CATS:\n",
        "                            self.catcount += 1\n",
        "                        elif label == self.DOGS:\n",
        "                            self.dogcount += 1\n",
        "                    \n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                        #print(label, f, str(e))\n",
        "        \n",
        "        np.random.shuffle(self.training_data) #performs in-place shuffling\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        print('Cats:',dogsvcats.catcount)\n",
        "        print('Dogs:',dogsvcats.dogcount)\n",
        "\n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CRBwvIYG41r",
        "outputId": "d634e173-d768-4a45-e74b-233a7c46be70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24946\n",
            "(24946, 2)\n",
            "[array([[ 70,  65,  57, ..., 224, 223, 227],\n",
            "       [103, 110, 115, ..., 226, 224, 222],\n",
            "       [130, 139, 145, ..., 226, 228, 229],\n",
            "       ...,\n",
            "       [158, 163, 184, ..., 189, 233, 230],\n",
            "       [120, 141, 151, ..., 184, 231, 230],\n",
            "       [117, 134, 167, ...,  13, 223, 227]], dtype=uint8)\n",
            " array([1., 0.])]\n"
          ]
        }
      ],
      "source": [
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "# call load_data with allow_pickle implicitly set to true\n",
        "training_data = np.load(\"training_data.npy\")\n",
        "\n",
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old\n",
        "\n",
        "print(len(training_data))\n",
        "print(training_data.shape)\n",
        "print(training_data[2]) #3rd training example is a cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "dciU_DrBG41r",
        "outputId": "e58ff2e2-4361-4182-9939-52e5604652c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Now let's take a peak at one of our samples:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(training_data[2][0], cmap=\"gray\")\n",
        "print(training_data[2][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sdHETFigG41s"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # just run the init of parent class (nn.Module)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels i.e number of kernels, 5x5 kernel / window\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 conv\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "        \n",
        "        #we need to flatten the output of conv layer before feeding into the dense layer. But there exists no .Flatten() func as in tensorflow. So basically we want to know self.fc1 = nn.Linear(????, 512)\n",
        "        #Let's craete random data and check the output size after passing it through first 3 layers conv layers\n",
        "        x = torch.randn(50,50).view(-1,1,50,50) #this would be the actual input to our CNN. 1 in 1,50,50 corresponds to the same 1 as in 1,32,5 of first layer of CNN\n",
        "        self._to_linear = None\n",
        "        self.convs(x) #calls the conv() func which passing the randomly created data through first 3 layers conv layers and stores output size into _to_linear\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
        "\n",
        "\n",
        "\n",
        "    def convs(self, x): # just the forward method but it would run through just the top 3 conv layers and compute the output\n",
        "        # max pooling over 2x2\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) #(2,2) is the shape of pooling\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
        "\n",
        "        #print('Shape is',x[0].shape)\n",
        "        if self._to_linear is None:\n",
        "            #typically x will be (batch_size,x,y,z). So x[0] takes the first image of the batch.\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "net=Net()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(device) #pushes our entire network on the GPU i.e cuda 0. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYEfKRmVId7-",
        "outputId": "d6cf6f4c-7437-4348-892e-cb6ea5207c67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we had multiple GPU's we could put our entire training data as well on the other GPU eg cuda1. Here since we have just 1 GPU we will have to put both the model and training data in bactches on the same GPU"
      ],
      "metadata": {
        "id": "kt1huAuLKW1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "05BaKdBqG41x"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss() #beacuse the lables here are one-hot encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ7aKRErG41x",
        "outputId": "aa993c5c-3004-4cf8-fd06-9d084a7e2a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NH31XrMG41y",
        "outputId": "8329aa1b-1271-4e22-81fe-3148c2f239eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2494\n",
            "22452 2494\n"
          ]
        }
      ],
      "source": [
        "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "print(val_size)\n",
        "\n",
        "train_X = X[:-val_size]\n",
        "train_y = y[:-val_size]\n",
        "\n",
        "test_X = X[-val_size:]\n",
        "test_y = y[-val_size:]\n",
        "print(len(train_X), len(test_X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3Ngo7JfG41y",
        "outputId": "0ed73e07-aa1e-4506-c03b-26a78090d53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:04<00:00, 49.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 0.054462507367134094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:04<00:00, 50.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1. Loss: 0.042431943118572235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225/225 [00:04<00:00, 50.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2. Loss: 0.038210947066545486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50]\n",
        "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
        "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50).to(device)\n",
        "        batch_y = train_y[i:i+BATCH_SIZE].to(device)\n",
        "\n",
        "        net.zero_grad()\n",
        "\n",
        "        outputs = net(batch_X)\n",
        "        loss = loss_function(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()    # Does the update\n",
        "\n",
        "    print(f\"Epoch: {epoch}. Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJhzIMWqG41z",
        "outputId": "b2d6d78b-288d-4807-a8a5-dd45aa8996ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [00:05<00:00, 438.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(len(test_X))):\n",
        "        real_class = torch.argmax(test_y[i]).to(device)\n",
        "        net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]  # returns a list, \n",
        "        predicted_class = torch.argmax(net_out)\n",
        "\n",
        "        if predicted_class == real_class:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "print(\"Accuracy: \", round(correct/total, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysamcdZvG411"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "4a20f9aec864725aaab65e871419d99cbd7cf3d5ab0d2e7243b7ef9750fa61ca"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit ('pixsy_work': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Convnet_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}