{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "REBUILD_DATA = True # set to true once, then back to false after you have created/processed your data unless you want to change something in your training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#creates an array of size 3 and one-hot encodes it at specifies index\n",
    "a=np.eye(3)[0]\n",
    "b=np.eye(3)[2]\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12501/12501 [01:30<00:00, 137.63it/s]\n",
      "100%|██████████| 12501/12501 [01:24<00:00, 147.61it/s]\n",
      "C:\\Users\\shubh\\Desktop\\Pixsy\\ml-retraining\\pixsy_work\\lib\\site-packages\\numpy\\lib\\npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats: 12476\n",
      "Dogs: 12470\n"
     ]
    }
   ],
   "source": [
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"PetImages/Cat\"\n",
    "    DOGS = \"PetImages/Dog\"\n",
    "    TESTING = \"PetImages/Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "                        \n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))\n",
    "        \n",
    "        np.random.shuffle(self.training_data) #performs in-place shuffling\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print('Cats:',dogsvcats.catcount)\n",
    "        print('Dogs:',dogsvcats.dogcount)\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n",
      "(24946, 2)\n",
      "[array([[ 70,  65,  57, ..., 224, 223, 227],\n",
      "        [103, 110, 115, ..., 226, 224, 222],\n",
      "        [130, 139, 145, ..., 226, 228, 229],\n",
      "        ...,\n",
      "        [158, 163, 184, ..., 189, 233, 230],\n",
      "        [120, 141, 151, ..., 184, 231, 230],\n",
      "        [117, 134, 167, ...,  13, 223, 227]], dtype=uint8) array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "print(len(training_data))\n",
    "print(training_data.shape)\n",
    "print(training_data[2]) #3rd training example is a cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now let's take a peak at one of our samples:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_data[2][0], cmap=\"gray\")\n",
    "print(training_data[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels i.e number of kernels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 conv\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        \n",
    "        #we need to flatten the output of conv layer before feeding into the dense layer. But there exists no .Flatten() func as in tensorflow. So basically we want to know self.fc1 = nn.Linear(????, 512)\n",
    "        #Let's craete random data and check the output size after passing it through first 3 layers conv layers\n",
    "        x = torch.randn(50,50).view(-1,1,50,50) #this would be the actual input to our CNN. 1 in 1,50,50 corresponds to the same 1 as in 1,32,5 of first layer of CNN\n",
    "        self._to_linear = None\n",
    "        self.convs(x) #calls the conv() func which passing the randomly created data through first 3 layers conv layers and stores output size into _to_linear\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "\n",
    "\n",
    "    def convs(self, x): # just the forward method but it would run through just the top 3 conv layers and compute the output\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) #(2,2) is the shape of pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        #print('Shape is',x[0].shape)\n",
    "        if self._to_linear is None:\n",
    "            #typically x will be (batch_size,x,y,z). So x[0] takes the first image of the batch.\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "net=Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got shape as 128,2,2 which was kind of expected because the output of last conv layer is 128 and 2,2 is the pooling applied on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss() #beacuse the lables here are one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n",
      "22452 2494\n"
     ]
    }
   ],
   "source": [
    "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)\n",
    "\n",
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "print(len(train_X), len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:42<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.2466684728860855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50]\n",
    "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "    print(f\"Epoch: {epoch}. Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [00:05<00:00, 449.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \n",
    "        predicted_class = torch.argmax(net_out)\n",
    "\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a20f9aec864725aaab65e871419d99cbd7cf3d5ab0d2e7243b7ef9750fa61ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('pixsy_work': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
